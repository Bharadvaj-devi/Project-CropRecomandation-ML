{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3f1143eb-923b-4574-97fe-94aee1326fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central Tendency Measures:\n",
      "Mean: 40\n",
      "Median: 45.0\n",
      "Mode: 50\n",
      "\n",
      "Measure of Dispersion:\n",
      "Variance: 377.77777777777777\n",
      "Standard Deviation: 19.436506316151\n"
     ]
    }
   ],
   "source": [
    "import statistics as st\n",
    "\n",
    "# Input: List of numbers\n",
    "data = [10, 20, 20, 30, 40, 50, 50, 50, 60, 70]\n",
    "\n",
    "# Central Tendency Measures\n",
    "mean = st.mean(data)\n",
    "median = st.median(data)\n",
    "mode = st.mode(data)\n",
    "\n",
    "# Measure of Dispersion\n",
    "variance = st.variance(data)\n",
    "std_dev = st.stdev(data)\n",
    "\n",
    "# Output Results\n",
    "print(\"Central Tendency Measures:\")\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Median: {median}\")\n",
    "print(f\"Mode: {mode}\")\n",
    "\n",
    "print(\"\\nMeasure of Dispersion:\")\n",
    "print(f\"Variance: {variance}\")\n",
    "print(f\"Standard Deviation: {std_dev}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a8ed9d-451f-4475-8b61-70970696d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "\n",
    "# Sample dataset\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # Independent variable\n",
    "y = np.array([2, 4, 5, 4, 5])                # Dependent variable\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Visualization\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X, y, color=\"blue\", label=\"Data Points\")\n",
    "plt.plot(X, model.predict(X), color=\"red\", label=\"Regression Line\")\n",
    "plt.title(\"Simple Linear Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Output the metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a483021c-b3bc-45d4-882f-af386b6ae411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics Library Example:\n",
      "Mean: 6, Median: 6, Mode: 4\n",
      "Variance: 8, Standard Deviation: 2.8284271247461903\n",
      "\n",
      "Math Library Example:\n",
      "0.7071067811865476\n",
      "Square Root: 4.0, Power: 32.0\n",
      "Logarithm: 2.0, Factorial: 120, Sin(30°): 0.49999999999999994\n",
      "\n",
      "NumPy Library Example:\n",
      "Array: [1 2 3 4 5]\n",
      "Sum: 15, Mean: 3.0, Std Dev: 1.4142135623730951\n",
      "Squared Array: [ 1  4  9 16 25]\n",
      "Matrix Transpose:\n",
      "[[1 3]\n",
      " [2 4]]\n",
      "\n",
      "SciPy Library Example:\n",
      "Mode: ModeResult(mode=3, count=3)\n",
      "Z-Scores: [-1.6081688  -0.75047877 -0.75047877  0.10721125  0.10721125  0.10721125\n",
      "  0.96490128  1.82259131]\n",
      "Determinant of Matrix:\n",
      "-2.0\n"
     ]
    }
   ],
   "source": [
    "import statistics as stats\n",
    "\n",
    "data = [2, 4, 4, 6, 8, 8, 10]\n",
    "\n",
    "# Basic Statistical Measures\n",
    "mean = stats.mean(data)\n",
    "median = stats.median(data)\n",
    "mode = stats.mode(data)\n",
    "variance = stats.variance(data)\n",
    "std_dev = stats.stdev(data)\n",
    "\n",
    "print(\"Statistics Library Example:\")\n",
    "print(f\"Mean: {mean}, Median: {median}, Mode: {mode}\")\n",
    "print(f\"Variance: {variance}, Standard Deviation: {std_dev}\")\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "# Math Operations\n",
    "sqrt_val = math.sqrt(16)\n",
    "power = math.pow(2, 5)\n",
    "log_val = math.log(100, 10)  # Logarithm base 10\n",
    "factorial = math.factorial(5)\n",
    "sin_val = math.sin(math.radians(30))  # Sin of 30 degrees\n",
    "\n",
    "print(\"\\nMath Library Example:\")\n",
    "print(math.cos(math.radians(45)))\n",
    "print(f\"Square Root: {sqrt_val}, Power: {power}\")\n",
    "print(f\"Logarithm: {log_val}, Factorial: {factorial}, Sin(30°): {sin_val}\")\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Creating Arrays\n",
    "array = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Array Operations\n",
    "sum_array = np.sum(array)\n",
    "mean_array = np.mean(array)\n",
    "std_array = np.std(array)\n",
    "squared = np.square(array)\n",
    "\n",
    "# Working with Matrices\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "transpose = np.transpose(matrix)\n",
    "\n",
    "print(\"\\nNumPy Library Example:\")\n",
    "print(f\"Array: {array}\")\n",
    "print(f\"Sum: {sum_array}, Mean: {mean_array}, Std Dev: {std_array}\")\n",
    "print(f\"Squared Array: {squared}\")\n",
    "print(f\"Matrix Transpose:\\n{transpose}\")\n",
    "\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "data = [1, 2, 2, 3, 3, 3, 4, 5]\n",
    "\n",
    "# Statistical Analysis\n",
    "mode = stats.mode(data)\n",
    "z_scores = stats.zscore(data)\n",
    "\n",
    "# Linear Algebra (from SciPy.linalg)\n",
    "from scipy.linalg import det\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "determinant = det(matrix)\n",
    "\n",
    "print(\"\\nSciPy Library Example:\")\n",
    "print(f\"Mode: {mode}\")\n",
    "print(f\"Z-Scores: {z_scores}\")\n",
    "print(f\"Determinant of Matrix:\\n{determinant}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0bcd4c77-b92b-4896-a024-800f597cb5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pivoted DataFrame:\n",
      "City        Los Angeles  New York\n",
      "Date                             \n",
      "2024-01-01           75        32\n",
      "2024-01-02           77        35\n",
      "\n",
      "Merged DataFrame:\n",
      "   ID   Name  Score\n",
      "0   1  Alice     90\n",
      "1   2    Bob     80\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "data = {\n",
    "    'Date': ['2024-01-01', '2024-01-02', '2024-01-01', '2024-01-02'],\n",
    "    'City': ['New York', 'New York', 'Los Angeles', 'Los Angeles'],\n",
    "    'Temperature': [32, 35, 75, 77]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Pivot\n",
    "pivoted = df.pivot(index='Date', columns='City', values='Temperature')\n",
    "\n",
    "print(\"\\nPivoted DataFrame:\")\n",
    "print(pivoted)\n",
    "\n",
    "\n",
    "# Create two DataFrames\n",
    "df1 = pd.DataFrame({'ID': [1, 2], 'Name': ['Alice', 'Bob']})\n",
    "df2 = pd.DataFrame({'ID': [1, 2], 'Score': [90, 80]})\n",
    "\n",
    "# Merge\n",
    "merged = pd.merge(df1, df2, on='ID')\n",
    "\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "print(merged)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2167a3-407c-4053-a557-5588ac22d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"Age\": [25, 30, 35],\n",
    "    \"Salary\": [50000, 60000, 70000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Accessing data\n",
    "print(\"DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nAccess Age column:\", df[\"Age\"])\n",
    "\n",
    "# Add a new column\n",
    "df[\"Bonus\"] = df[\"Salary\"] * 0.1\n",
    "print(\"\\nDataFrame with Bonus column:\")\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "# Read CSV file\n",
    "# df = pd.read_csv(\"data.csv\")  # Replace 'data.csv' with your file\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "df.to_csv(\"output.csv\", index=False)\n",
    "print(\"\\nData has been saved to output.csv.\")\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Alice\", \"Charlie\", \"Bob\"],\n",
    "    \"Age\": [25, 30, 25, 35, 30],\n",
    "    \"Salary\": [50000, 60000, 52000, 70000, 60000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Group by Name and find average salary\n",
    "grouped = df.groupby(\"Name\")[\"Salary\"].mean()\n",
    "\n",
    "print(\"\\nGrouped Data:\")\n",
    "print(grouped)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Plot\n",
    "plt.plot(x, y, label=\"y = 2x\", color=\"blue\", marker=\"o\")\n",
    "plt.title(\"Line Plot Example\")\n",
    "plt.xlabel(\"X-axis\")\n",
    "plt.ylabel(\"Y-axis\")\n",
    "plt.legend()\n",
    "# plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Data\n",
    "categories = [\"A\", \"B\", \"C\"]\n",
    "values = [10, 20, 15]\n",
    "\n",
    "# Plot\n",
    "plt.bar(categories, values, color=\"green\")\n",
    "plt.title(\"Bar Chart Example\")\n",
    "plt.xlabel(\"Categories\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.show()\n",
    "# Data\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Scatter Plot\n",
    "plt.scatter(x, y, color=\"red\")\n",
    "plt.title(\"Scatter Plot Example\")\n",
    "plt.xlabel(\"X-axis\")\n",
    "plt.ylabel(\"Y-axis\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "data = np.random.randn(1000)  # 1000 random numbers\n",
    "\n",
    "# Plot Histogram\n",
    "plt.hist(data, bins=30, color=\"purple\", edgecolor=\"black\")\n",
    "plt.title(\"Histogram Example\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e965539-3e70-4f21-8205-b2538b206fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Sample dataset\n",
    "data = pd.DataFrame({\n",
    "    \"Size\": [1400, 1600, 1700, 1875, 1100],\n",
    "    \"Bedrooms\": [3, 3, 4, 3, 2],\n",
    "    \"Age\": [10, 5, 15, 20, 25],\n",
    "    \"Price\": [245000, 312000, 279000, 308000, 199000]\n",
    "})\n",
    "\n",
    "# EDA: Correlation heatmap\n",
    "sns.heatmap(data.corr(), annot=True)\n",
    "plt.title(\"Feature Correlation\")\n",
    "plt.show()\n",
    "\n",
    "# Features and target\n",
    "X = data[[\"Size\", \"Bedrooms\",'Age']]\n",
    "y = data[\"Price\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8334abeb-eca1-4b07-8ccf-ef6bf99d2f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Static dataset\n",
    "data = {\n",
    "    \"Email Length\": [50, 60, 70, 100, 120, 150, 170, 200, 220, 250],\n",
    "    \"Has Link\": [1, 0, 1, 1, 0, 1, 0, 1, 0, 1],  # 1 = Yes, 0 = No\n",
    "    \"Is Spam\": [1, 0, 1, 1, 0, 1, 0, 1, 0, 1],  # 1 = Spam, 0 = Not Spam\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Features (X) and Labels (y)\n",
    "X = df[[\"Email Length\", \"Has Link\"]]\n",
    "y = df[\"Is Spam\"]\n",
    "\n",
    "# Decision Tree Classifier\n",
    "model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy Score:\", accuracy_score(y, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y, y_pred))\n",
    "\n",
    "# Visualize the Decision Tree\n",
    "plt.figure(figsize=(4, 4))\n",
    "plot_tree(model, feature_names=[\"Email Length\", \"Has Link\"], class_names=[\"Not Spam\", \"Spam\"], filled=True)\n",
    "plt.title(\"Decision Tree for Email Classification\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d7098a-76b7-43d6-953f-6f4ca8ee5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dataset\n",
    "data={\n",
    "    \n",
    "}\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(model, filled=True, feature_names=data.feature_names, class_names=data.target_names)\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4912d93-33fd-4833-b33a-666c44c8a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Step 2: Hyperparameter Tuning using GridSearchCV\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters found by GridSearchCV\n",
    "print(\"Best Parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Train the best model\n",
    "best_dt = grid_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred_best = best_dt.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"\\nClassification Report (Best Model):\\n\", classification_report(y_test, y_pred_best))\n",
    "print(\"Accuracy Score (Best Model):\", accuracy_score(y_test, y_pred_best))\n",
    "\n",
    "# Confusion Matrix for best model\n",
    "cm_best = confusion_matrix(y_test, y_pred_best)\n",
    "print(\"Confusion Matrix (Best Model):\\n\", cm_best)\n",
    "\n",
    "# Step 3: Visualizing the Decision Tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(best_dt, filled=True, feature_names=data.feature_names, class_names=data.target_names, rounded=True)\n",
    "plt.title(\"Best Decision Tree Model\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5cc03-5bdf-48be-8254-2802bbf36da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c984893-9bde-4ac1-9293-a02a034e97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Dataset\n",
    "# data = load_iris()\n",
    "# X = data.data\n",
    "# y = (data.target == 2).astype(int)  # Binary classification: class 2 or not\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Model\n",
    "# model = LogisticRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Predictions\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# # Step 2: EDA - Visualizing Feature Distribution and Target Classes\n",
    "# sns.scatterplot(data=data, x=\"x\", y=\"y\", hue=\"Target\", palette=\"coolwarm\")\n",
    "# plt.title(\"Feature Distribution by Target Class\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = (data.target == 2).astype(int)  # Binary classification: class 2 or not\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 2: EDA - Visualizing Feature Distribution and Target Classes\n",
    "# Create a DataFrame for easier handling in seaborn\n",
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "df['Target'] = y\n",
    "\n",
    "# Visualize two features, let's choose 'sepal length' and 'sepal width'\n",
    "sns.scatterplot(data=df, x=\"sepal length (cm)\", y=\"sepal width (cm)\", hue=\"Target\", palette=\"coolwarm\")\n",
    "plt.title(\"Feature Distribution by Target Class\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b9ea6c-ae2c-4c17-ac5a-e6cec70e0553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Static dataset (Messages and Labels)\n",
    "data = {\n",
    "    'Message': [\n",
    "        'Free money!!!',\n",
    "        'Hi, how are you?',\n",
    "        'Get cheap loans now',\n",
    "        'Hello, want to grab lunch?',\n",
    "        'Earn money fast, click here',\n",
    "        'Free offer just for you',\n",
    "        'Your order has been shipped',\n",
    "        'Congratulations, you won a prize!',\n",
    "        'Important: Your account has been compromised',\n",
    "        'Have you finished the project?',\n",
    "    ],\n",
    "    'Label': [\n",
    "        1,  # Spam\n",
    "        0,  # Ham\n",
    "        1,  # Spam\n",
    "        0,  # Ham\n",
    "        1,  # Spam\n",
    "        1,  # Spam\n",
    "        0,  # Ham\n",
    "        1,  # Spam\n",
    "        0,  # Ham\n",
    "        0,  # Ham\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Features (X) and Labels (y)\n",
    "X = df['Message']\n",
    "y = df['Label']\n",
    "\n",
    "# Convert text data into numerical data (Bag of Words)\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_vect = vectorizer.fit_transform(X)\n",
    "# print(X)\n",
    "# print(X_vect)\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42bded5-d00e-4706-ae9d-12b92be4d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Static dataset\n",
    "data = {\n",
    "    \"Salary\": [20000, 25000, 30000, 35000, 40000, 45000, 50000, 55000, 60000, 65000],\n",
    "    \"Buy\": [0, 0, 0, 1, 0, 1, 1, 1, 1, 1],  # 0 = Not Buy, 1 = Buy\n",
    "}\n",
    "\n",
    "# Features (X) and Labels (y)\n",
    "X = np.array(data[\"Salary\"]).reshape(-1, 1)\n",
    "y = np.array(data[\"Buy\"])\n",
    "\n",
    "# Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy Score:\", accuracy_score(y, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y, y_pred))\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(data[\"Salary\"], data[\"Buy\"], color=\"blue\", label=\"Data Points\")\n",
    "plt.plot(data[\"Salary\"], model.predict_proba(X)[:, 1], color=\"red\", label=\"Logistic Curve\")\n",
    "plt.title(\"Logistic Regression: Buy or Not\")\n",
    "plt.xlabel(\"Salary\")\n",
    "plt.ylabel(\"Probability of Buying\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ff3bd3-2ecf-46e1-88c3-a5283fce481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Static dataset (Messages and Labels)\n",
    "data = {\n",
    "    'Message': [\n",
    "        'Free money!!!',\n",
    "        'Hi, how are you?',\n",
    "        'Get cheap loans now',\n",
    "        'Hello, want to grab lunch?',\n",
    "        'Earn money fast, click here',\n",
    "        'Free offer just for you',\n",
    "        'Your order has been shipped',\n",
    "        'Congratulations, you won a prize!',\n",
    "        'Important: Your account has been compromised',\n",
    "        'Have you finished the project?',\n",
    "    ],\n",
    "    'Label': [\n",
    "        1,  # Spam\n",
    "        0,  # Ham\n",
    "        1,  # Spam\n",
    "        0,  # Ham\n",
    "        1,  # Spam\n",
    "        1,  # Spam\n",
    "        0,  # Ham\n",
    "        1,  # Spam\n",
    "        0,  # Ham\n",
    "        0,  # Ham\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ------------------- EDA -------------------\n",
    "\n",
    "# Check the distribution of labels\n",
    "sns.countplot(data=df, x='Label', palette='coolwarm')\n",
    "plt.title('Distribution of Spam (1) and Ham (0) Messages')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Add message length as a feature\n",
    "df['Message_Length'] = df['Message'].apply(len)\n",
    "\n",
    "# Visualize message length distribution\n",
    "sns.histplot(df, x='Message_Length', hue='Label', bins=10, kde=True, palette='coolwarm')\n",
    "plt.title('Message Length Distribution')\n",
    "plt.xlabel('Message Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Basic statistics\n",
    "print(\"Basic statistics for message lengths:\")\n",
    "print(df.groupby('Label')['Message_Length'].describe())\n",
    "\n",
    "# ------------------- Preprocessing -------------------\n",
    "\n",
    "# Features (X) and Labels (y)\n",
    "X = df['Message']\n",
    "y = df['Label']\n",
    "\n",
    "# Convert text data into numerical data (Bag of Words)\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_vect = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ------------------- Model Training -------------------\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ------------------- Evaluation -------------------\n",
    "\n",
    "# Accuracy Score\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# ------------------- ROC Curve -------------------\n",
    "\n",
    "# Probability predictions for ROC\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa5026-2ca8-4c65-aef2-72b8202d31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "\n",
    "# Dataset\n",
    "X, _ = make_blobs(n_samples=300, centers=3, cluster_std=0.6, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = KMeans(n_clusters=3, random_state=42)\n",
    "y_kmeans = model.fit_predict(X)\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, cmap='viridis')\n",
    "plt.scatter(model.cluster_centers_[:, 0], model.cluster_centers_[:, 1], s=300, c='red', label='Centroids')\n",
    "plt.title(\"K-Means Clustering\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697b494-a4e7-4154-9ab5-2243601d7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dataset as a dictionary\n",
    "data = {\n",
    "    \"Feature_1\": np.random.uniform(1, 10, 300),  # Random values for Feature 1\n",
    "    \"Feature_2\": np.random.uniform(1, 10, 300),  # Random values for Feature 2\n",
    "}\n",
    "\n",
    "# Convert dictionary to numpy array for K-Means\n",
    "X = np.column_stack((data[\"Feature_1\"], data[\"Feature_2\"]))\n",
    "\n",
    "# Model\n",
    "model = KMeans(n_clusters=3, random_state=42)\n",
    "y_kmeans = model.fit_predict(X)\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, cmap='viridis')\n",
    "plt.scatter(model.cluster_centers_[:, 0], model.cluster_centers_[:, 1], s=300, c='red', label='Centroids')\n",
    "plt.title(\"K-Means Clustering\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafad96a-2fc3-4a3f-9d71-73ff10749acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Static dataset as a dictionary\n",
    "data = {\n",
    "    \"Feature_1\": [2, 3, 5, 8, 9, 4, 10, 12, 15, 11],\n",
    "    \"Feature_2\": [1, 4, 7, 6, 8, 3, 9, 10, 13, 11],\n",
    "}\n",
    "\n",
    "# Convert dictionary to numpy array for K-Means\n",
    "X = np.column_stack((data[\"Feature_1\"], data[\"Feature_2\"]))\n",
    "\n",
    "# K-Means model\n",
    "model = KMeans(n_clusters=3, random_state=42)\n",
    "y_kmeans = model.fit_predict(X)\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, cmap='viridis', label='Data Points')\n",
    "plt.scatter(model.cluster_centers_[:, 0], model.cluster_centers_[:, 1], s=300, c='red', label='Centroids')\n",
    "plt.title(\"K-Means Clustering\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec40dbb-9750-4a4c-9886-72c04ce34ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate a simple 2D dataset for classification\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create and train the KNN model\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# --- Visualization ---\n",
    "\n",
    "# Plotting the dataset\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot training data points\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, marker='o', label='Train Data', alpha=0.7)\n",
    "\n",
    "# Plot test data points\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, marker='x', label='Test Data', alpha=0.7)\n",
    "\n",
    "# Decision boundaries\n",
    "h = 0.02  # Step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Plot decision boundary\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"K-Nearest Neighbors (KNN) Classification\")\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b02e26-6926-42a4-bf52-733ab1e0e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# from sklearn.datasets import make_classification\n",
    "# Generate a simple dataset\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train KNN model\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Visualize decision boundary and data points\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.5, cmap=\"coolwarm\")\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"coolwarm\", edgecolor=\"k\")\n",
    "plt.title(\"K-Nearest Neighbors (KNN) Simplified Visualization\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405e4afa-054b-4c72-9407-71aa03846ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9613aab0-b235-43b0-85d3-1f2998309ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "\n",
    "# Sample dataset\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # Independent variable\n",
    "y = np.array([2, 4, 5, 4, 5])                # Dependent variable\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Visualization\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X, y, color=\"blue\", label=\"Data Points\")\n",
    "plt.plot(X, model.predict(X), color=\"red\", label=\"Regression Line\")\n",
    "plt.title(\"Simple Linear Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Output the metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
